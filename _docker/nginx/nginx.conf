# user www-data;
worker_processes auto;

error_log stderr warn;
pid /run/nginx.pid;

# Number of file descriptors used for Nginx. This is set in the OS with 'ulimit -n 200000'
# or using /etc/security/limits.conf
# 2x worker_connections below is recommended
worker_rlimit_nofile 2048;

events {
  # essential for linux, optmized to serve many clients with each thread
  # use epoll;

  # Determines how many clients will be served by each worker process.
  # (Max clients = worker_connections * worker_processes)
  # "Max clients" is also limited by the number of socket connections available on the system (~64k)
  worker_connections 1024;

  # Accept as many connections as possible.
  multi_accept on;
}

http {
  # MIME types.
  include /etc/nginx/mime.types;
  default_type application/octet-stream;

  # Define custom log format to include reponse times
  log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent $request_time "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

  # Define custom log format to include reponse times
  log_format main_timed '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for" '
                        '$request_time $upstream_response_time $pipe $upstream_cache_status';

  map $request $loggable {
    ~*elb-status 0;
    default 1;
  }

  map $upstream_http_content_type $cache_html {
    default 0;
    text/html 1;
  }

  access_log /dev/stdout main_timed if=$loggable;
  error_log /dev/stderr warn;

  # Write temporary files to /tmp so they can be created as a non-privileged user
  client_body_temp_path /tmp/client_temp;
  proxy_temp_path /tmp/proxy_temp_path;
  fastcgi_temp_path /tmp/fastcgi_temp;
  uwsgi_temp_path /tmp/uwsgi_temp;
  scgi_temp_path /tmp/scgi_temp;

  # Handling of IPs in proxied and load balancing situations.
  # set_real_ip_from 0.0.0.0/32; # all addresses get a real IP.
  # real_ip_header X-Forwarded-For; # the ip is forwarded from the load balancer/proxy
  # https://serverfault.com/questions/331531/nginx-set-real-ip-from-aws-elb-load-balancer-address
  # NOTE: 2023-09-22 - since we can guarantee that all traffic will be coming
  # via either the ALB / or Cloudfront - we can set set_real_ip_from 0.0.0.0/0;
  
  # Set to the IPv4 CIDR of our AWS VPC
  # set_real_ip_from 172.31.0.0/16;
  # NOTE: only set 0.0.0.0/0 if you trust the ELB/ALB or proxy to prevent spoofing
  # set_real_ip_from 172.31.0.0/16;

  # Cloudflare IPs - Last updated 2025-05-23
  # Source: https://www.cloudflare.com/ips/
  # set_real_ip_from 0.0.0.0/0; 
  # real_ip_header X-Forwarded-For;
  # real_ip_recursive on;

  # IPv4
  set_real_ip_from 103.21.244.0/22;
  set_real_ip_from 103.22.200.0/22;
  set_real_ip_from 103.31.4.0/22;
  set_real_ip_from 104.16.0.0/13;
  set_real_ip_from 104.24.0.0/14;
  set_real_ip_from 108.162.192.0/18;
  set_real_ip_from 131.0.72.0/22;
  set_real_ip_from 141.101.64.0/18;
  set_real_ip_from 162.158.0.0/15;
  set_real_ip_from 172.64.0.0/13;
  set_real_ip_from 173.245.48.0/20;
  set_real_ip_from 188.114.96.0/20;
  set_real_ip_from 190.93.240.0/20;
  set_real_ip_from 197.234.240.0/22;
  set_real_ip_from 198.41.128.0/17;

  # IPv6
  set_real_ip_from 2400:cb00::/32;
  set_real_ip_from 2405:8100::/32;
  set_real_ip_from 2405:b500::/32;
  set_real_ip_from 2606:4700::/32;
  set_real_ip_from 2803:f800::/32;
  set_real_ip_from 2a06:98c0::/29;
  set_real_ip_from 2c0f:f248::/32;

  real_ip_header X-Forwarded-For;
  real_ip_recursive on;

  # Define a zone for limiting the number of simultaneous
  # connections nginx accepts. 1m means 32000 simultaneous
  # sessions. We need to define for each server the limit_conn
  # value refering to this or other zones.
  # ** This syntax requires nginx version >=
  # ** 1.1.8. Cf. http://nginx.org/en/CHANGES. If using an older
  # ** version then use the limit_zone directive below
  # ** instead. Comment out this
  # ** one if not using nginx version >= 1.1.8.
  limit_conn_zone $binary_remote_addr zone=perip:10m;

  # Define a zone for rate limiting requests per IP 
  limit_req_zone $binary_remote_addr zone=baserate:10m rate=20r/s;

  # Define a zone for rate limiting requests per IP for security sensitive areas
  limit_req_zone $binary_remote_addr zone=securerate:10m rate=3r/s;

  # Define a zone for rate limiting good bots.
  limit_req_zone $good_bot zone=goodbot:10m rate=2r/s;

  # Timeouts.

  # Specifies how long to wait for the client to send a request header (e.g.: GET / HTTP/1.1).
  # This timeout is reached only if a header is not received in one read (needs clarification).
  # If the client has not sent anything within this timeout period, nginx returns the HTTP
  # status code 408 ("Request timed out")
  client_header_timeout 30;

  # Directive sets the read timeout for the request body from client.
  # The timeout is set only if a body is not get in one readstep. If after this time the
  # client send nothing, nginx returns error "Request time out" (408).
  client_body_timeout 30;


  # The first parameter assigns the timeout for keep-alive connections with the client.
  # The server will close connections after this time. The optional second parameter assigns the
  # time value in the header Keep-Alive: timeout=time of the response. This header can convince
  # some browsers to close the connection, so that the server does not have to. Without this
  # parameter, nginx does not send a Keep-Alive header (though this is not what makes a connection "keep-alive").
  # The parameters can differ from each other.
  keepalive_timeout 30 30;

  # If the client stops reading data, free up the stale client connection after this much time. Default 60.
  send_timeout 30;

  # Number of requests a client can make over the keep-alive connection. This is set high for testing.
  # keepalive_requests 100000;
  keepalive_requests 1000;

  # Reset lingering timed out connections. Deflect DDoS.
  reset_timedout_connection on;

  # Sendfile copies data between one FD and other from within the kernel.
  # More efficient than read() + write(), since the requires transferring data to and from the user space.
  sendfile on;

  # don't buffer data-sends (disable Nagle algorithm). Good for sending frequent small bursts of data in real time.
  tcp_nodelay on;

  # Tcp_nopush causes nginx to attempt to send its HTTP response head in one packet,
  # instead of using partial frames. This is useful for prepending headers before calling sendfile,
  # or for throughput optimization.
  tcp_nopush on;

  # Compression.
  gzip on;
  gzip_buffers 16 8k;
  gzip_comp_level 2;
  gzip_http_version 1.1;
  gzip_min_length 1024;
  gzip_types text/plain application/json text/css application/javascript application/x-javascript text/xml application/xml application/xml+rss text/javascript image/x-icon application/vnd.ms-fontobject font/opentype application/x-font-ttf image/svg+xml;
  gzip_vary on;
  # Compression for all requests.
  gzip_proxied any; 
  # No need for regexps. See
  # http://wiki.nginx.org/NginxHttpGzipModule#gzip_disable
  gzip_disable "msie6";

  # Serve already compressed files directly, bypassing on-the-fly
  # compression.
  #
  # Usually you don't make much use of this. It's better to just
  # enable gzip_static on the locations you need it.
  # gzip_static on;

  # Hide the Nginx version number.
  server_tokens off;

  #ssl_protocols TLSv1.2 TLSv1.3;
  #ssl_prefer_server_ciphers on;
  #ssl_session_tickets on;
  # Diffie-Hellman parameter for DHE ciphersuites, recommended 2048 bits
  #ssl_dhparam /etc/nginx/ssl/dhparam.pem;

  # Use a SSL/TLS cache for SSL session resume. This needs to be
  # here (in this context, for session resumption to work. See this
  # thread on the Nginx mailing list:
  # http://nginx.org/pipermail/nginx/2010-November/023736.html.
  #ssl_session_cache shared:SSL:50m;
  #ssl_session_timeout 60m;

  # intermediate configuration. tweak to your needs.
  # ssl_ciphers ECDH+AESGCM:ECDH+AES256-CBC:ECDH+AES128-CBC:DH+3DES:!ADH:!AECDH:!MD5;

  # HSTS (ngx_http_headers_module is required) (15768000 seconds = 6 months)
  #add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

  # Uncomment to increase map_hash_bucket_size. If start getting
  # [emerg]: could not build the map_hash, you should increase
  # map_hash_bucket_size: 64 in your
  # logs. Cf. http://wiki.nginx.org/NginxOptimizations.
  #map_hash_bucket_size 192;

  # Increase variable hash size since we've already run over
  # the default.
  variables_hash_max_size 1024;

  # For the filefield_nginx_progress module to work. From the
  # README. Reserve 1MB under the name 'uploads' to track uploads.
  # upload_progress uploads 1m;


  # Enable clickjacking protection in modern browsers. Available in
  # IE8 also. See
  # https://developer.mozilla.org/en/The_X-FRAME-OPTIONS_response_header
  # This may conflicts with pseudo streaming (at least with Nginx version 1.0.12).
  # Uncomment the line below if you're not using media streaming.
  # For sites *using* frames uncomment the line below.
  # add_header X-Frame-Options SAMEORIGIN;
  # For sites *not* using frames uncomment the line below.
  #add_header X-Frame-Options DENY;

  # Block MIME type sniffing on IE.
  # add_header X-Content-Options nosniff;

  # If using Nginx version >= 1.1.11 then there's a $https variable
  # that has the value 'on' if the used scheme is https and '' if not.
  # See: http://trac.nginx.org/nginx/changeset/4380/nginx
  # http://trac.nginx.org/nginx/changeset/4333/nginx and
  # http://trac.nginx.org/nginx/changeset/4334/nginx. If using a
  # previous version then uncomment out the line below.
  #include map_https_fcgi.conf;

  # Include this line, if used in a loadbalanced environment
  # and comment the line which includes map_https_fcgi.conf.
  # If the loadbalancer always sends the request in http protocol,
  # and adds the server variable $http_x_forwarded_proto
  #include map_https_forwarded_proto.conf;

  # Include the upstream servers for Apache handling the PHP
  # processes. In this case Nginx functions as a reverse proxy.
  #include reverse_proxy.conf;
  #include upstream_phpapache.conf;

  # Include the php-fpm status allowed hosts configuration block.
  # Uncomment to enable if you're running php-fpm.
  #include php_fpm_status_allowed_hosts.conf;

  # Include the Nginx stub status allowed hosts configuration block.
  include /etc/nginx/nginx_status_allowed_hosts.conf;

  # If you want to run cron using Drupal cron.php. i.e., you're not
  # using drush then uncomment the line below. Specify in
  # cron_allowed_hosts.conf which hosts can invole cron.
  # include apps/drupal/cron_allowed_hosts.conf;

  # Include the upstream servers for PHP FastCGI handling
  # configuration. This setup uses UNIX sockets for talking with the
  # upstream.
  # include /etc/nginx/upstream_phpcgi_unix.conf;

  # Include the map to block HTTP methods.
  # include /etc/nginx/map_block_http_methods.conf;

  # Include control for good bots, bad bots and referrers.
  include /etc/nginx/botlist.conf;

  # Include blocked IP addresses
  include /etc/nginx/blockips.conf;

  # Include the caching setup. Needed for using Drupal with an external cache.
  # include /etc/nginx/map_cache.conf;

  # Microcache zone definition for FastCGI.
  # include /etc/nginx/fastcgi_microcache_zone.conf;

  # If you're using Apache for handling PHP then comment the line
  # above and uncomment the line below.
  #include proxy_microcache_zone.conf

  # More privacy focused Referrer policy setting
  # https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy
  # add_header Referrer-Policy strict-origin-when-cross-origin;

  # Proxy cache path for all html requests
  # proxy_cache_path /var/run/nginx-cache/html levels=1:2 keys_zone=html:10m inactive=5s max_size=10m use_temp_path=off ;

  # Nginx status
  server {
    listen 127.0.0.1:8001;
    server_name localhost;
    location /nginx_status {
        stub_status on;
        access_log   off;
        allow 127.0.0.1;
        deny all;
    }
  }

  # Default server definition
  server {
    # listen [::]:8000 default_server;
    listen 8000 default_server;
    server_name _;
    root /app/public;
  
    # Will limit the number of simultaneous connections from a single IP address as tracked
    # in the  limit_conn_zone $binary_remote_addr zone=perip:10m; definition.
    # NOTE: 2023-09-22 - see the note above on set_real_ip_from
    # NOTE: should be set to a value that is slightly greater or equal to the maximum number
    # of parallel requests a browser can make.
    # https://saturncloud.io/blog/max-parallel-http-connections-in-a-browser-what-you-need-to-know/
    limit_conn perip 70;

    # Sets buffer size for reading client request body. In case the request body is larger 
    # than the buffer, the whole body or only its part is written to a temporary file. 
    # By default, buffer size is equal to two memory pages. This is 8K on x86, other 32-bit platforms, 
    # and x86-64. It is usually 16K on other 64-bit platforms.
    # 2023-06-12 - set to 1M to accomdate larger JSON document submissions from Payload CMS
    client_body_buffer_size 1M;

    # Sets the maximum allowed size of the client request body. If the size in a request 
    # exceeds the configured value, the 413 (Request Entity Too Large) error is returned 
    # to the client. Please be aware that browsers cannot correctly display this error. 
    # Setting size to 0 disables checking of client request body size.
    client_max_body_size 100M;

    include /etc/nginx/denials.conf;

    # Set cache key based on the URI and the theme cookie or header
    # set $cache_key "$scheme://$host$request_uri";
    # set $theme "";

    # Try sec_ch_prefers_color_scheme as fallback if no cookie below
    # if ($http_sec_ch_prefers_color_scheme) {
    #     set $theme "_$http_sec_ch_prefers_color_scheme";
    # }

    # Now check for a cookie which if present will override sec_ch_prefers_color_scheme
    # if ($http_cookie ~* "theme=([^;]+)") {
    #     set $theme "_$1";
    # }

    # set $cache_key "${cache_key}${theme}";

    # Nginx location exact match using = - will termination location evaluation here.
    location = /elb-status {
      # Disable basic auth for elb-status health checks
      auth_basic off;
      proxy_pass http://127.0.0.1:3000/elb-status;
      include /etc/nginx/proxy_nodejs.conf;
    }

    location = /robots.txt {
      # Disable basic auth robots.txt and do not set expires
      auth_basic off;
      access_log off;
    }
    
    # Our main url rewrite block. If the uri is not a file, then
    # try sending this to @nodejs.
    #
    # NOTE: 2023-09-22 - we nest all of the regex attempted matches below within
    # the location / {} block, so that any regular path matches here,
    # and in the server / site configuration will take priority.
    # Otherwise the regex expressions will evaluate first, and 
    # certain paths or aliases in the site config will never match.
    # https://nginx.org/en/docs/http/ngx_http_core_module.html#location
    location / {

      # Rate limit to our base rate zone above
      # See baserate zone above
      # TODO: Disabled for benchmarking - remember to turn back on!
      limit_req zone=baserate burst=70 nodelay;
      limit_req zone=goodbot burst=3 nodelay;
      limit_req_status 429;

      # Any requests to /build or /fonts are cached max and served by nginx
      location ~ ^/(fonts/) {
        access_log off;
        expires 1y;
        try_files $uri @nodejs_cached;
      }

      # All other requests
      expires 30d;
      try_files $uri @nodejs_cached;
    }

    # Nodejs named location and proxy configuration
    location @nodejs {
      proxy_pass http://127.0.0.1:3000;
      proxy_buffering off;
      include /etc/nginx/proxy_nodejs.conf;
    }

    # Nodejs named location and proxy configuration
    # Proxy buffer / buffers strategy
    # https://www.getpagespeed.com/server-setup/nginx/tuning-proxy_buffer_size-in-nginx
    location @nodejs_cached {
      proxy_buffering on;
      # should be enough for most Next.js/SSR/PHP websites, or adjust as above
      proxy_buffer_size 16k; 
      # essentially, proxy_buffer_size + 2 small buffers of 4k
      proxy_busy_buffers_size 24k;
      # should be enough for most Next.js/SSR/PHP websites, adjust as above to get an accurate value
      proxy_buffers 64 4k; 
      proxy_pass http://127.0.0.1:3000;
      include /etc/nginx/proxy_nodejs.conf;
    }
  }
}